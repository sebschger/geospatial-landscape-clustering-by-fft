{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c45ce995",
   "metadata": {},
   "source": [
    "# Landscape Clustering by FFT Footprints\n",
    "## Primary Notebook\n",
    "\n",
    "Hi! This project is a personal project with a fun backstory. Have you ever been on vacation and wondered: Do I really have to travel this far, or is there a similar landscape closeer to my home delivering the same experience? Well I know this to be a really unusual question, but one that I asked myself, while on vacation all over Scotland.\n",
    "\n",
    "This project aims to make similar \"landscape types\" easy to discover. Essentially the notebook creates one or more GeoTIFFs where different landscape types are colored. They are clustered by their topographic footprint.\n",
    "\n",
    "### The topographic footprint\n",
    "\n",
    "\n",
    "### Overview: \n",
    "This is the primary notebook of this repository, and the one that does the heavy work.\n",
    "\n",
    "There are other notebooks to this repository:\n",
    "- secondary_dem_retriever.ipynb -> This one connects to opentopography.org and retrieves DEM geotiffs (aka heightmaps) of parts of the earth.\n",
    "- color_separator.ipynb -> This is just a little helper notebook (only rough code). This one helped creating custom color palettes for coloring the resulting images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a574dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we might need eventually\n",
    "# rasterio for geotiffs\n",
    "# dask array for parallel computing of large arrays\n",
    "# pyfftw for 2d fft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2bb14b",
   "metadata": {},
   "source": [
    "## Overview of the classes and their interconnection\n",
    "The subject of this notebook is to cluster different landscapes across multiple DEM-GeoTIFFs. \n",
    "\n",
    "### GeographicBounds\n",
    "This is an object that saves West, South, East, North bounds, as well as the projection, and maybe some other additional info.\n",
    "\n",
    "### AugmentedDEM\n",
    "This will be the \"container\" for all information regarding *one* specific DEM raster map.\n",
    "\n",
    "### EmbeddingMap\n",
    "This will be part of each AugmentedDEM. Here we will save the labels created by the clustering.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485369e7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc9a77bc",
   "metadata": {},
   "source": [
    "## How to make the GeoTIFF images usable by my algorithm:\n",
    "It’s important to note, that the original DEM data is in arc seconds. To avoid skewed results it has to be compressed by cos(latitude) in width.  That way the metric distances (almost) resemble the distances pixel-wise\n",
    "\n",
    "After that the images will be scaled to 1/4 (as of now), because processing becomes about 4^2 times faster.\n",
    "\n",
    "Before processing, the data will have to be split up into quadratic tiles which are supposed to be equal in their length.\n",
    "\n",
    "I guess we should combine the processes, namely selecting tiles of equal size and then reducing their size to a given size in pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eaa0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Filesystem, JSON\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# Rasterio for handling GeoTIFFs\n",
    "import rasterio\n",
    "from rasterio.transform import Affine, from_origin\n",
    "\n",
    "from rasterio.warp import calculate_default_transform, transform_bounds, reproject, Resampling\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.enums import Resampling as ResampleEnum\n",
    "\n",
    "\n",
    "# Resampling of the tiles\n",
    "from PIL import Image \n",
    "\n",
    "\n",
    "# For interpolation of the results\n",
    "from scipy.interpolate import griddata\n",
    "from scipy import ndimage # for filtering\n",
    " \n",
    "\n",
    "# Math may not be missing\n",
    "import math\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import pyfftw \n",
    "\n",
    "\n",
    "# The heart: we use k-means-clustering\n",
    "from sklearn.cluster import KMeans\n",
    "import hdbscan\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "# Regex for updating filenames\n",
    "import re\n",
    "\n",
    "\n",
    "# For earth related numbers\n",
    "from pyproj import Geod, CRS, Transformer\n",
    "geod = Geod(ellps = \"WGS84\")\n",
    "\n",
    "\n",
    "# Matplotlib for graphics\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "# For timing \n",
    "import time\n",
    "\n",
    "\n",
    "# For multiprocessing\n",
    "from multiprocess import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646078e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# A simple limit function for integers\n",
    "def clamp(x, min, max) -> int:\n",
    "                return int(sorted([min,x,max])[1])\n",
    "\n",
    "\n",
    "def mode_filter(label_map, radius = 10) -> np.ndarray:\n",
    "    '''\n",
    "    Returns the most prevalent label in a given radius inside a label map.\n",
    "    The label map has to be in shape (y,x), the label values can be arbitrary integers.\n",
    "    '''\n",
    "    y, x = np.ogrid[-radius:radius+1, -radius:radius+1]\n",
    "    mask = x**2 + y**2 <= radius **2\n",
    "\n",
    "\n",
    "    def mode_filter_func(values):\n",
    "        counts = np.bincount(values.astype(\"uint8\"))\n",
    "        return np.argmax(counts)\n",
    "    \n",
    "    filtered = ndimage.generic_filter(\n",
    "        label_map,\n",
    "        function = mode_filter_func,\n",
    "        footprint = mask,\n",
    "        mode = \"nearest\"\n",
    "    )\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "\n",
    "def constrain_labels(input) -> list:\n",
    "    '''\n",
    "    Takes a list of integer labels in any range and converts them to 1, 2, 3…\n",
    "    '''\n",
    "\n",
    "    unique_labels = np.sort(np.unique(input))\n",
    "    new_labels = np.arange(0,len(unique_labels), 1)\n",
    "    from_to = dict(zip(unique_labels,new_labels))\n",
    "\n",
    "    constrained_labels = np.vectorize(from_to.get)(input)\n",
    "\n",
    "    return constrained_labels\n",
    "\n",
    "\n",
    "\n",
    "def color_to_numpy(stringlist) -> np.ndarray:\n",
    "    '''\n",
    "    This converts a list of string hex color codes to actual rgb values in a numpy array.\n",
    "    '''\n",
    "\n",
    "    colorlist = np.empty((len(stringlist),3))\n",
    "\n",
    "    for i, string in enumerate(stringlist):\n",
    "        removed_hashtag = re.search(r\"(?i)([a-f0-9]+)\", string).group(0)\n",
    "        colorlist[i] = np.array((int(removed_hashtag[0:2],16),\n",
    "                        int(removed_hashtag[2:4],16),\n",
    "                        int(removed_hashtag[4:6],16)))\n",
    "\n",
    "    return colorlist\n",
    "\n",
    "\n",
    "\n",
    "def euclidean_distance (y_a, y_b, x_a, x_b) -> float:\n",
    "    '''\n",
    "    Calculates the pythagorean distance between two points.\n",
    "    '''\n",
    "\n",
    "    return math.sqrt((y_a-y_b)**2 + (x_a-x_b)**2)\n",
    "\n",
    "\n",
    "\n",
    "def threshold (input, threshold, bandwidth = 1) -> float:\n",
    "    '''\n",
    "    Creates smooth edges in the circle masks.\n",
    "    Values below threshold become 0, values above 1.\n",
    "    Values at the threshold ± half bandwidth are faded.\n",
    "    '''\n",
    "\n",
    "    # This is essentially anti aliasing without subsampling.\n",
    "\n",
    "    result = np.interp(input, [threshold-(bandwidth/2), threshold+(bandwidth/2)], [0,1])\n",
    "    return result;\n",
    "\n",
    "\n",
    "\n",
    "def sort_labels(labels):\n",
    "    '''Rearrange label ids by their group size'''\n",
    "    unique, counts = np.unique(labels, return_counts = True)\n",
    "    size_order = np.argsort(-counts)\n",
    "\n",
    "    lookup = np.empty_like(unique)\n",
    "    lookup[size_order] = np.arange(len(size_order))\n",
    "\n",
    "    relabeled = lookup[labels]\n",
    "    return relabeled\n",
    "\n",
    "def CircleImage (height, width, radius, inverted = False, bandwidth = 1) -> np.ndarray:\n",
    "\n",
    "    '''\n",
    "    Returns an antialiased image of a circle with a given radius as a numpy array for masking.\n",
    "    '''\n",
    "\n",
    "    # Height, width defines the shape of the 'image'\n",
    "    # Inverted flips colors\n",
    "    # The bandwidth defines the width of a smooth edge of the circle (for anti aliasing)\n",
    "\n",
    "    circle_image = np.zeros((height, width))\n",
    "\n",
    "    if radius == 0:\n",
    "        return (1 - circle_image) if inverted else (circle_image)\n",
    "    else:\n",
    "        for x in range(width):\n",
    "            for y in range(height):\n",
    "                circle_image[y,x] = euclidean_distance(\n",
    "                    y+(0.5 if height%2 == 1 else 0), height / 2,\n",
    "                    x+(0.5 if width%2 == 1 else 0), width / 2\n",
    "                )\n",
    "\n",
    "    if inverted:\n",
    "        return 1-threshold(circle_image, radius, 1)\n",
    "    else:\n",
    "        return threshold(circle_image, radius, 1)\n",
    "\n",
    "\n",
    "\n",
    "def RingImage (height, width, inner_radius, outer_radius, bandwidth) -> np.ndarray:\n",
    "\n",
    "    '''\n",
    "    Utilizes two circles to create a ring mask with smooth edges.\n",
    "    Please look into CircleImage for in-depth definition.\n",
    "    '''\n",
    "\n",
    "    if outer_radius < inner_radius:\n",
    "        raise ValueError(\"The inner radius must be smaller than the outer radius.\")\n",
    "\n",
    "    # This combines two circles to form a ring mask\n",
    "    outercircle = CircleImage(height, width, outer_radius, \n",
    "                              inverted = True, bandwidth = bandwidth)\n",
    "    innercircle = CircleImage(height, width, inner_radius, \n",
    "                              inverted = True, bandwidth = bandwidth)\n",
    "    \n",
    "    ringimg = outercircle - innercircle\n",
    "\n",
    "    return  (ringimg - ringimg.min()) / (ringimg.max() - ringimg.min())\n",
    "\n",
    "\n",
    "\n",
    "def RingImageSeries(height,width,steps,bandwidth) -> np.ndarray:\n",
    "\n",
    "    '''\n",
    "    This creates a 3D numpy array of the shape\n",
    "    (Masks, individual Height, individual Width)\n",
    "    This is used to sum and average the FFT magnitudes\n",
    "    '''\n",
    "\n",
    "    # The diameter gets bigger logarithmically, starting with a diameter of 1\n",
    "    smallest_side = min(height,width)\n",
    "\n",
    "    outer_radii = np.logspace(0, np.log2(smallest_side / 2), steps, base = 2) # 0 means it starts with 1 (log)\n",
    "    inner_radii = np.append(0,outer_radii[:-1])\n",
    "\n",
    "\n",
    "    all_masks = np.zeros((steps,height, width))\n",
    "\n",
    "    for i in range(steps):\n",
    "        all_masks[i] = RingImage(height,width,inner_radii[i],outer_radii[i],bandwidth = bandwidth)\n",
    "            \n",
    "    return all_masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30601272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper classes\n",
    "\n",
    "\n",
    "class SimpleTimer:\n",
    "    '''This class is just a timer for checking the performance'''\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, description):\n",
    "        self.description = description\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.timer = time.perf_counter()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.time_needed = time.perf_counter() - self.timer\n",
    "        print(f\"{self.description} took {self.time_needed:.1f} Seconds\")\n",
    "\n",
    "\n",
    "\n",
    "class VerboseInfoTimer:\n",
    "    '''\n",
    "    This class wraps processes to help identifying what is done by printing info about them.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, process_description: str, current_index: int = 1, total_count: int = 1, single_description: str | None = None):\n",
    "        self.sd = single_description\n",
    "        self.pd = process_description\n",
    "        self.curr_it = current_index + 1\n",
    "        self.total_count = total_count\n",
    "        self.rest = total_count - self.curr_it\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.timer = time.perf_counter()\n",
    "\n",
    "        if self.total_count > 1:\n",
    "            if self.curr_it == 1:\n",
    "                print(f\"\\n{self.pd} starting…\\n\")\n",
    "            print(f\"{self.sd} {self.curr_it} of {self.total_count}…\")\n",
    "        else:\n",
    "            print(f\"{self.pd} starting…\")\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.time_needed = time.perf_counter() - self.timer\n",
    "\n",
    "        if self.total_count > 1:\n",
    "            print(f\"{self.sd} completed. This one took {self.time_needed:.1f} seconds.\")\n",
    "\n",
    "            if self.rest > 0:\n",
    "                print(f\"{self.rest} more to go.\")\n",
    "            else:\n",
    "                print(f\"{self.pd} ({self.total_count}) completed.\")\n",
    "        else:\n",
    "            print(f\"{self.pd} completed. This group {self.time_needed:.1f} seconds.\")\n",
    "\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1956f9",
   "metadata": {},
   "source": [
    "<a id = \"settings\">Anchor</a>\n",
    "## Code explanation: Settings\n",
    "The following section sets the parameters for the main functions. I chose dictionaries to later be able to import and export JSON configs easily. \n",
    "\n",
    "In general there are **internal_settings** that control the execution, as well as **temporary_data** in which the intermediary results will be stored.\n",
    "\n",
    "The execution of the processing pipeline starts [at the end of the notebook](#execution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddca61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for running this Notebook\n",
    "\n",
    "internal_settings = {}\n",
    "\n",
    "internal_settings[\"files\"] = {}\n",
    "internal_settings[\"files\"][\"dem_folder\"] = \"input_geotiffs\" #Here the to-be-used-geotiffs are located\n",
    "\n",
    "internal_settings[\"fft\"] = {}\n",
    "internal_settings[\"fft\"][\"tile_size_km\"] = 9 # 9 average length and width of a tile that is processed individually\n",
    "internal_settings[\"fft\"][\"tile_size_px\"] = 20 # 20\n",
    "\n",
    "internal_settings[\"fft\"][\"tile_overlap_percent\"] = 95 # 95 How much (by a tile length in percent) do the tiles overlap\n",
    "internal_settings[\"fft\"][\"fft_levels\"] = 14  # 14\n",
    "\n",
    "internal_settings[\"output\"] = {}\n",
    "internal_settings[\"output\"][\"folder_name\"] = \"output_label_images\" \n",
    "internal_settings[\"output\"][\"q_factor\"] = 10 # 5 Bigger Q-Factor, smaller image result, faster computation\n",
    "internal_settings[\"output\"][\"label_mode_filter\"] = 4  # 20 this is in arbitrary units. It will adapt to the final size, so bigger images are filtered in the same way\n",
    "internal_settings[\"output\"][\"label_count\"] = 10 # 10 as for now\n",
    "\n",
    "# Speed settings to quickly test things. Just set to True\n",
    "if False:\n",
    "    internal_settings[\"fft\"][\"tile_size_km\"] = 15\n",
    "    internal_settings[\"fft\"][\"tile_overlap_percent\"] = 65 # 85 How much (by a tile length in percent) do the tiles overlap\n",
    "\n",
    "# This one calculates the actual filter size in pixels regarding the final image\n",
    "internal_settings[\"output\"][\"label_mode_filter_radius\"] = int(internal_settings[\"output\"][\"label_mode_filter\"] / (internal_settings[\"output\"][\"q_factor\"] / 5))\n",
    "internal_settings[\"fft\"][\"tile_overlap_multi\"] = 1 / (1 - (internal_settings[\"fft\"][\"tile_overlap_percent\"]/100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfba279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes specific to this project\n",
    "\n",
    "class GeographicCoordinate:\n",
    "    '''Stores coordinates and their respective coordinate system.'''\n",
    "\n",
    "    def __init__ (self, x, y, crs):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.crs = crs\n",
    "\n",
    "    def in_another_crs(self, dst_crs):\n",
    "        '''Reproject the same coordinates into another coordinate system'''\n",
    "\n",
    "        intermediary_transformer = Transformer.from_crs(self.crs, dst_crs, always_xy = True)\n",
    "        projected_bounds = intermediary_transformer.transform(self.x, self.y)\n",
    "\n",
    "        return GeographicCoordinate(*projected_bounds,dst_crs)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"X: {self.x:.1f}, Y: {self.y:.1f}\"\n",
    "\n",
    "\n",
    "class GeographicBounds:\n",
    "    '''\n",
    "    Stores bounds for both the dem maps and also the tiles.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, xmin, ymin, xmax, ymax, crs, transform = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.crs = crs\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    # Convert the bounds to another coordinate system / projection\n",
    "    def in_another_crs(self, dst_crs):\n",
    "        '''Reproject the same bounds into another coordinate system'''\n",
    "\n",
    "        projected_bounds = transform_bounds(self.crs, dst_crs, *self.bounds, densify_pts = 10) \n",
    "        # Densify helps keeping bulges from reprojecting inside the bounds. We try 10, if it’s too bad we improve it.\n",
    "\n",
    "        return GeographicBounds(*projected_bounds, dst_crs)\n",
    "\n",
    "\n",
    "    # Give back a tuple of bounds\n",
    "    @property\n",
    "    def bounds (self): \n",
    "        return (self.xmin,self.ymin,self.xmax,self.ymax)\n",
    "\n",
    "    # Center along x extent (undefined unit. can be degrees, metres,…)\n",
    "    @property\n",
    "    def center_x (self): \n",
    "        return (self.xmin+self.xmax)/2\n",
    "\n",
    "\n",
    "    # Center along y extent (undefined unit. can be degrees, metres,…)\n",
    "    @property\n",
    "    def center_y (self): \n",
    "        return (self.ymin+self.ymax)/2\n",
    "\n",
    "\n",
    "    # This is a projected coordinate system for reprojecting the DEM file to\n",
    "    # The so reprojected image is where the individual tiles are taken from \n",
    "    @property\n",
    "    def intermediary_aeqd_crs (self):\n",
    "        return CRS.from_proj4(\n",
    "        f\"+proj = aeqd +lat_0 = {self.in_another_crs(CRS('EPSG:4326')).center_y} +lon_0 = {self.in_another_crs(CRS('EPSG:4326')).center_x} \"\n",
    "        \"x_0 = 0 +y_0 = 0 +ellps = WGS84 +units = m +no_defs +type = crs\")\n",
    "\n",
    "    def get_bound_length(self, side: str):\n",
    "        '''You can ask for the side (left, top, right, bottom) and get the length in km in return'''\n",
    "\n",
    "        if self.crs.is_geographic:\n",
    "            if side == \"left\":\n",
    "                _, _, distance = geod.inv(self.xmin, self.ymin, self.xmin, self.ymax)\n",
    "            elif side == \"top\":\n",
    "                _, _, distance = geod.inv(self.xmin, self.ymax, self.xmax, self.ymax)\n",
    "            elif side == \"right\":\n",
    "                _, _, distance = geod.inv(self.xmax, self.ymin, self.xmax, self.ymax)\n",
    "            elif side == \"bottom\":\n",
    "                _, _, distance = geod.inv(self.xmin, self.ymin, self.xmax, self.ymin)\n",
    "            else:\n",
    "                raise ValueError(\"The argument for side is not valid.\")\n",
    "        elif self.crs.is_projected:\n",
    "\n",
    "            if side == \"left\":\n",
    "                distance = abs(self.ymax-self.ymin)\n",
    "            elif side == \"top\":\n",
    "                distance = abs(self.xmax-self.xmin)\n",
    "            elif side == \"right\":\n",
    "                distance = abs(self.ymax-self.ymin)\n",
    "            elif side == \"bottom\":\n",
    "                distance = abs(self.xmax-self.xmin)\n",
    "            else:\n",
    "                raise ValueError(\"The argument for side is not valid.\")\n",
    "        else:\n",
    "            raise ValueError(\"CRS is neither projected nor geographic.\")\n",
    "        \n",
    "        return distance\n",
    "    \n",
    "\n",
    "    def get_projected_extent(self):\n",
    "            '''Returns width and height in km of the azimuthal equidistant projected bounds (x,y) as a tuple.'''\n",
    "\n",
    "            # If this bounds object refers to geographic bounds, rerun the function on the converted bounds recursively.\n",
    "            # I think this is ingenious of me ha ha, if it not fails however... ^^\n",
    "\n",
    "            if self.crs.is_geographic:\n",
    "                return self.in_another_crs(self.intermediary_aeqd_crs).get_projected_extent()\n",
    "            elif self.crs.is_projected:\n",
    "                return (abs(self.xmax-self.xmin), abs(self.ymax-self.ymin))\n",
    "            else: \n",
    "                raise ValueError(\"Coordinate system seems broken. Neither geographic nor projected.\")\n",
    "            \n",
    "\n",
    "\n",
    "    # Return information about the object (for to be used in a print statement for example)\n",
    "    def __str__(self):\n",
    "        infostring = \"Infos about the GeographicBounds (all rounded):\\n\"\n",
    "        infostring += f\"-----\\n\"\n",
    "        infostring += f\"Geographic Bounds:\\n\"\n",
    "        infostring += f\"X Min: {self.xmin:>7.2f} \\n\"\n",
    "        infostring += f\"Y Min: {self.ymin:>7.2f} \\n\"\n",
    "        infostring += f\"X Max: {self.xmax:>7.2f} \\n\"\n",
    "        infostring += f\"Y Max: {self.ymax:>7.2f}\\n\"\n",
    "        infostring += f\"-----\\n\"\n",
    "        infostring += f\"Left Width: {self.get_bound_length('left'):.2f} m\\n\"\n",
    "        infostring += f\"Bottom Width: {self.get_bound_length('bottom'):.2f} m\\n\"\n",
    "        infostring += f\"Right Width: {self.get_bound_length('right'):.2f} m\\n\"\n",
    "        infostring += f\"Top Width: {self.get_bound_length('top'):.2f} m\\n\"\n",
    "        infostring += f\"-----\\n\"\n",
    "        infostring += f\"Center: {self.center_y:.3f} (Y), {self.center_x:.3f} (X)°\\n\"\n",
    "        infostring += \"\\n\"\n",
    "        return infostring\n",
    "\n",
    "\n",
    "    def as_list(self):\n",
    "        return [self.xmin, self.ymin, self.xmax, self.ymax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b1f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The heart of the algorithm\n",
    "\n",
    "class AugmentedDEM:\n",
    "    '''\n",
    "    Handles the segmentation and individual processing of each GeoTIFF (aka DEM map).\n",
    "    '''\n",
    "    # Settings will be handed over before the processing begins\n",
    "    settings = None\n",
    "\n",
    "    def __init__(self, dem_path):\n",
    "        '''\n",
    "        Load key metadata from the GeoTIFF at the specified filepath.\n",
    "        '''\n",
    "    \n",
    "        # Hint: No DEM data is loaded until processing.\n",
    "        with rasterio.open(dem_path) as dem_file:\n",
    "            self.src_crs = dem_file.crs\n",
    "            \n",
    "            \n",
    "            # Save the geographic WGS84 bounds in a new nested object\n",
    "            self.geo_bounds = GeographicBounds(dem_file.bounds.left, \n",
    "                                               dem_file.bounds.bottom,\n",
    "                                               dem_file.bounds.right,\n",
    "                                               dem_file.bounds.top,\n",
    "                                               dem_file.crs,\n",
    "                                               dem_file.transform)\n",
    "            \n",
    "            # Save the original dimensions inside this object\n",
    "            self.dem_width_px = dem_file.width\n",
    "            self.dem_height_px = dem_file.height\n",
    "        \n",
    "        # Save the original path for later \n",
    "        self.dem_path = dem_path\n",
    "\n",
    "\n",
    "    def _resample_original_dem(self):\n",
    "        # This is part of the fast pipeline\n",
    "        '''Takes the original dem and reprojects it to azimuthal equidistant.\n",
    "        This might lead to inaccuracies at the bounds. However those inaccuracies\n",
    "        are negligible, that the areas labeled will fall into the right categories.'''\n",
    "\n",
    "        with rasterio.open(self.dem_path) as src:\n",
    "\n",
    "            tile_size_px = int(self.settings[\"fft\"][\"tile_size_px\"])\n",
    "\n",
    "            intermediary_geo_bounds = self.geo_bounds.in_another_crs(self.geo_bounds.intermediary_aeqd_crs)\n",
    "            dst_crs = intermediary_geo_bounds.crs\n",
    "\n",
    "            target_res = (self.settings[\"fft\"][\"tile_size_km\"] * 1000) / self.settings[\"fft\"][\"tile_size_px\"] \n",
    "            # Metres per pixel\n",
    "\n",
    "            scaled_transform, projected_dem_width_pixels, projected_dem_height_pixels = \\\n",
    "            calculate_default_transform(\n",
    "            src.crs, dst_crs, src.width, src.height, *src.bounds, resolution = target_res, densify_pts=101\n",
    "            )\n",
    "\n",
    "            projected_dem = np.empty((src.count, projected_dem_height_pixels, projected_dem_width_pixels))\n",
    "\n",
    "\n",
    "            for i in range(1, src.count + 1):\n",
    "                    reproject(\n",
    "                        source=rasterio.band(src, i),\n",
    "                        destination=projected_dem[i-1],\n",
    "                        src_transform=src.transform,\n",
    "                        src_crs=src.crs,\n",
    "                        dst_transform=scaled_transform,\n",
    "                        dst_crs=dst_crs,\n",
    "                        resampling=ResampleEnum.bilinear\n",
    "                    )\n",
    "\n",
    "            # Set the number of tiles, the projected DEM map will be split into\n",
    "            tile_multiplier = internal_settings[\"fft\"][\"tile_overlap_multi\"]\n",
    "\n",
    "            num_tiles_x  = int((projected_dem_width_pixels // tile_size_px) * tile_multiplier)\n",
    "            num_tiles_y  = int((projected_dem_height_pixels // tile_size_px) * tile_multiplier)\n",
    "\n",
    "            # Set the starting positions of each tile\n",
    "            start_left = (projected_dem_width_pixels % tile_size_px) // 2\n",
    "            end_right = projected_dem_width_pixels - start_left - tile_size_px\n",
    "\n",
    "            start_top = (projected_dem_height_pixels % tile_size_px) // 2\n",
    "            end_bottom = projected_dem_height_pixels - start_top - tile_size_px\n",
    "            \n",
    "            tile_starts_x = np.linspace(start_left,end_right,num_tiles_x, endpoint=False)\n",
    "            tile_starts_y = np.linspace(start_top,end_bottom,num_tiles_y, endpoint=False)\n",
    "\n",
    "            tile_starts_x = tile_starts_x.astype(int)\n",
    "            tile_starts_y = tile_starts_y.astype(int)\n",
    "            \n",
    "\n",
    "            tile_starts_grid_x, tile_starts_grid_y = np.meshgrid(tile_starts_x, tile_starts_y)\n",
    "            \n",
    "            tile_starts_grid_xy = np.stack([tile_starts_grid_x.reshape(-1), \\\n",
    "                                            tile_starts_grid_y.reshape(-1)], axis = 1)\n",
    "\n",
    "            # Calculate the total number of tiles\n",
    "            num_tiles_total = num_tiles_x * num_tiles_y\n",
    "\n",
    "            # Create a list for the sample positions to later grid-interpolate from them\n",
    "            self.tile_centers_orig = []\n",
    "            \n",
    "            # Create the array for the resampled and reprojected tiles that later will be analyzed\n",
    "            self.tiles_resampled = np.zeros((num_tiles_total, tile_size_px, tile_size_px))\n",
    "\n",
    "\n",
    "            intermediary_transformer = Transformer.from_crs(dst_crs, self.geo_bounds.crs, always_xy = True)\n",
    "            \n",
    "            # Flip the projected DEM map vertically\n",
    "            projected_dem[0] = np.flip(projected_dem[0], axis=0)\n",
    "\n",
    "            # Create a random generator for scattering the sample points a bit\n",
    "            # This prevents the map from looking very \"pixelated\" and rather natural\n",
    "            # It scatters the sample points, not the results, so the results are still accurate\n",
    "            rng = np.random.default_rng()\n",
    "            \n",
    "            \n",
    "\n",
    "            with SimpleTimer(\"Calculating the center positions\"):\n",
    "                for i in range(num_tiles_total):\n",
    "\n",
    "                    # Create randomness as mentioned above for x and y coordinates\n",
    "                    random_shift = rng.uniform(-tile_size_px/2,tile_size_px/2,2)                        \n",
    "\n",
    "                    # Set up the horizontal bounds of the current tile\n",
    "                    x_base = tile_starts_grid_xy[i,0]+random_shift[0]\n",
    "                    x_base = clamp(x_base, start_left, end_right)\n",
    "                    x_start = x_base\n",
    "                    x_end = x_base + tile_size_px\n",
    "                    x_center = (x_start + x_end) // 2\n",
    "\n",
    "                    # Set up the vertical bounds of the current tile\n",
    "                    y_base = tile_starts_grid_xy[i,1] + random_shift[1]\n",
    "                    y_base = clamp(y_base, start_top, end_bottom)\n",
    "                    y_start = y_base\n",
    "                    y_end = y_base + tile_size_px\n",
    "                    y_center = (y_start + y_end) // 2\n",
    "\n",
    "                    # Extract the tiles\n",
    "                    self.tiles_resampled[i] = projected_dem[0][y_start:y_end, x_start:x_end]\n",
    "\n",
    "                    # Save the metric centerpoints relative to the center\n",
    "                    # to later infer the geographic position of the samples\n",
    "                    projected_x_center = (x_center - (projected_dem_width_pixels / 2)) * target_res\n",
    "                    projected_y_center = (y_center - (projected_dem_height_pixels / 2)) * target_res\n",
    "                \n",
    "                    # Append the geographic coordinates (relative to the source coordinate system)\n",
    "                    # to our list of the tile centers (which are the sample locations)\n",
    "                    # Optimization idea: this could be parallelized\n",
    "                    self.tile_centers_orig.append( GeographicCoordinate(*intermediary_transformer.transform(\\\n",
    "                        projected_x_center, projected_y_center), self.geo_bounds.crs) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _create_fft_tiles(self):\n",
    "        '''\n",
    "        This creates an 2D FFT magnitude map for each individual tile of the map.\n",
    "        '''\n",
    "        fft_input_array = pyfftw.empty_aligned((len(self.tiles_resampled),\n",
    "                                                self.settings[\"fft\"][\"tile_size_px\"],\n",
    "                                                self.settings[\"fft\"][\"tile_size_px\"]),\n",
    "                                                dtype = \"complex64\")\n",
    "\n",
    "        fft_output_array = pyfftw.empty_aligned((len(self.tiles_resampled),\n",
    "                                                self.settings[\"fft\"][\"tile_size_px\"],\n",
    "                                                self.settings[\"fft\"][\"tile_size_px\"]),\n",
    "                                                dtype = \"complex64\")\n",
    "\n",
    "        fft_execution_plan = pyfftw.FFTW(fft_input_array,\n",
    "                                        fft_output_array, axes = (1,2),\n",
    "                                        direction = \"FFTW_FORWARD\",\n",
    "                                        flags = (\"FFTW_MEASURE\",))\n",
    "\n",
    "        fft_input_array[:] = self.tiles_resampled #Important. [:] ensures the reserved empty array is used, and no new one is created! It will not work without that special slicing.\n",
    "\n",
    "        fft_execution_plan.execute()\n",
    "\n",
    "        fft_magnitude_spectra_unshifted = np.log(np.abs(fft_output_array) + 1) \n",
    "        self.fft_footprint = np.fft.fftshift(fft_magnitude_spectra_unshifted, axes = (1,2)) #Centered FFT\n",
    "\n",
    "\n",
    "        # Free memory. The resampled tiles are no longer needed\n",
    "        del self.tiles_resampled\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _bin_and_average_fft_tiles(self):\n",
    "        '''\n",
    "        This splits the FFT magnitude map for each tile into parts that average in a given distance.\n",
    "        This is essentially the \"FFT Footprint\".\n",
    "        The result will be a numpy array in the shape of (number_of_tiles, number_of_fft_levels)\n",
    "        '''\n",
    "\n",
    "        # Set up Dask Arrays for faster computation of the weighted averages\n",
    "\n",
    "\n",
    "        # The general dimensions are:\n",
    "        # 1. Number of tiles (total)\n",
    "        # 2. Height of a tile\n",
    "        # 3. Width of a tile\n",
    "        # 4. Number of levels (circle filters)\n",
    "\n",
    "        # To multiply and divide all the dimensions have to be in the same order for all arrays\n",
    "\n",
    "        # Weights – here go the circles\n",
    "        # Weights are still (#4, #2, #3), change them to #2, #3, #4\n",
    "\n",
    "\n",
    "        with SimpleTimer(\"Creating the weighted averages per mask\"):\n",
    "            \n",
    "            da_weights = da.from_array(\n",
    "                # The height becomes axis 0, width becomes axis 1, and different masks become axis 2\n",
    "                np.transpose(temporary_data[\"circle_masks\"],(1,2,0)) \n",
    "            )\n",
    "\n",
    "            # First dimension (#1) is missing, add it \n",
    "            # Just a note: the tiles themselves are not x-y adressed, but the get a continuous index (1D)\n",
    "            da_weights = da_weights[np.newaxis, ...]\n",
    "            # Now the form of the weights is (#1, #2, #3, #4) like explained above\n",
    "\n",
    "            # Take the results of the fft and place them also in a dask array\n",
    "            # of the wanted form (see above) \n",
    "            da_magnitude_spectra = da.from_array(self.fft_footprint)[...,np.newaxis]\n",
    "\n",
    "            # Sum the values of the areas covered by the circles, to later have something to divide by\n",
    "            # to generate weighted sums\n",
    "            da_weights_sum = da.sum(da_weights, axis = (1,2)) \n",
    "\n",
    "            # Sum the results of the FFTs multiplied by the weights of the different levels (circle filters)\n",
    "            da_sum_of_spectra = da.sum(da_magnitude_spectra * da_weights, axis = (1, 2))\n",
    "\n",
    "            # Calculate the weighted average \n",
    "            da_weighted_averages = da_sum_of_spectra / da_weights_sum\n",
    "\n",
    "            '''# Calculate the weighted variance \n",
    "            da_weighted_variance = da.sum(\n",
    "                da_weights * (da_magnitude_spectra - da_weighted_averages[:, np.newaxis, np.newaxis, :]) ** 2,\n",
    "                  axis=(1, 2)) / da_weights_sum'''\n",
    "\n",
    "            # The result is now in the shape of #1, #4 -> Number of Tiles, Number of Levels\n",
    "            self.fft_magnitude_all_levels = da_weighted_averages.compute() \n",
    "            # self.fft_magnitude_all_levels = da_weighted_variance.compute() \n",
    "\n",
    "\n",
    "    \n",
    "    def create_image(self):\n",
    "        '''\n",
    "        This method creates a colored image. \n",
    "        After the clustering has taken place the found labels will be translated to colors for each pixel.\n",
    "        '''\n",
    "\n",
    "        # Each tile has gotten a label\n",
    "        # We know the center of each tile\n",
    "        # That way we can interpolate an image by combining the two data sources\n",
    "        # Remember the tiles are not in a strict raster, because they become taller\n",
    "        # the closer they get to the equator.\n",
    "\n",
    "        position_tuple = [(tile.y, tile.x) for tile in self.tile_centers_orig]\n",
    "\n",
    "        # Calculate dimensions of the output image\n",
    "        output_pic_width = self.dem_width_px // self.settings[\"output\"][\"q_factor\"]\n",
    "        output_pic_height = self.dem_height_px // self.settings[\"output\"][\"q_factor\"]\n",
    "\n",
    "        # Set up grid for interpolating\n",
    "        tmp_grid_res_y = np.linspace(self.geo_bounds.ymax, self.geo_bounds.ymin, output_pic_height )\n",
    "        tmp_grid_res_x = np.linspace(self.geo_bounds.xmin, self.geo_bounds.xmax, output_pic_width )\n",
    "        tmp_grid_y, tmp_grid_x = np.meshgrid(tmp_grid_res_y, tmp_grid_res_x, indexing = \"ij\")\n",
    "\n",
    "        # Interpolate the data using the geographic positions of the sample points \n",
    "        # to the output image\n",
    "        output_image = griddata(position_tuple,\n",
    "        self.labels, (tmp_grid_y, tmp_grid_x), method = 'nearest') \n",
    "\n",
    "\n",
    "        with SimpleTimer(\"Filtering of the mapped labels\"):\n",
    "            # The mode filter smoothes the result in a way that \n",
    "            # it takes the mode in a certain radius (the values that are most common)\n",
    "            self.labels_interpolated = mode_filter(output_image, self.settings[\"output\"][\"label_mode_filter_radius\"])\n",
    "\n",
    "\n",
    "        # Start creating the image\n",
    "   \n",
    "        # I create my own color mapping for I like those colors\n",
    "        custom_colors_str = [\"#053608\" ,\n",
    "                            \"#bdf2e6\" ,\n",
    "                            \"#1c5532\" ,\n",
    "                            \"#62f8ee\" ,\n",
    "                            \"#ffba20\" ,\n",
    "                            \"#2c7eb5\" ,\n",
    "                            \"#b9c5d6\" ,\n",
    "                            \"#404383\" ,\n",
    "                            \"#91f88f\" ,\n",
    "                            \"#759d7c\" ,\n",
    "                            \"#9395a3\"  \n",
    "        ]\n",
    "\n",
    "        # The image becomes colors mapped from the custom colors indexed by the constrained labels\n",
    "        output_image_rgb = color_to_numpy(custom_colors_str)[constrain_labels(self.labels_interpolated)]\n",
    "        self.image_rgb = (np.transpose(output_image_rgb, (2,0,1))).astype(\"uint8\")\n",
    "\n",
    "\n",
    "    def write_image(self):\n",
    "        '''Writes the created image to the disk.'''\n",
    "\n",
    "        output_pic_width = self.dem_width_px // self.settings[\"output\"][\"q_factor\"]\n",
    "        output_pic_height = self.dem_height_px // self.settings[\"output\"][\"q_factor\"]\n",
    "\n",
    "        # Calculate pixel resolution for the GeoTIFF output image (degrees per pixel)\n",
    "        res_x = ((self.geo_bounds.xmax - self.geo_bounds.xmin) / output_pic_width)\n",
    "        res_y = ((self.geo_bounds.ymax - self.geo_bounds.ymin) / output_pic_height)\n",
    "\n",
    "        # Create affine transform (pixel coordinates → WGS84)\n",
    "        transform = self.geo_bounds.transform * Affine.scale(1*self.settings[\"output\"][\"q_factor\"])\n",
    "\n",
    "\n",
    "        # I put together a comprehensive (very long) filename to recall settings later\n",
    "        filename_string = os.path.basename(self.dem_path) + \\\n",
    "        f\"tlszkm {self.settings['fft']['tile_size_km']:.1f}  \" + \\\n",
    "        f\"tlszpx {self.settings['fft']['tile_size_px']:.0f}  \" + \\\n",
    "        f\"fftlvls {self.settings['fft']['fft_levels']:.0f}  \" + \\\n",
    "        f\"qfctr {self.settings['output']['q_factor']:.0f}  \" + \\\n",
    "        f\"{self.settings['fft']['tile_overlap_multi']:.1f}x \"+ \\\n",
    "        f\"-ovrlp-pct {self.settings['fft']['tile_overlap_percent']:.0f} \"+ \\\n",
    "        f\"fltrrds {self.settings['output']['label_mode_filter_radius']:.0f}\"+ \\\n",
    "        f\"lblct {self.settings['output']['label_count']:.0f}\"+ \\\n",
    "        f\".tif\"\n",
    "\n",
    "        filepath = os.path.join(self.settings[\"output\"][\"folder_name\"], filename_string)\n",
    "\n",
    "        # Write GeoTIFF\n",
    "        with rasterio.open(\n",
    "            filepath,\n",
    "            \"w\",\n",
    "            driver = \"GTiff\",\n",
    "            height = output_pic_height,\n",
    "            width = output_pic_width,\n",
    "            count = 3, \n",
    "            dtype = \"uint8\",\n",
    "            crs = self.geo_bounds.crs, \n",
    "            transform = transform,\n",
    "        ) as dst:\n",
    "            dst.write(self.image_rgb[0],1)\n",
    "            dst.write(self.image_rgb[1],2)\n",
    "            dst.write(self.image_rgb[2],3)\n",
    "\n",
    "\n",
    "        # Hereafter the clustering takes place (global via class method)\n",
    "        # After that each colored label map is written to the disk.\n",
    "\n",
    "    def process_dem_fast(self):\n",
    "        '''This is the faster and little less precise pipeline'''\n",
    "        \n",
    "        with SimpleTimer(\"Resampling the original DEM to azimuthal equidistant\"):\n",
    "            self._resample_original_dem()\n",
    "\n",
    "        with SimpleTimer(\"Creating FFT footprints\"):\n",
    "            self._create_fft_tiles()\n",
    "\n",
    "        with SimpleTimer(\"Binning and averaging FFT footprints\"):\n",
    "            self._bin_and_average_fft_tiles()\n",
    "        # Hereafter the clustering takes place (global via class method)\n",
    "        # After that each colored label map is written to the disk.\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def create_labels(cls, instances):\n",
    "        '''\n",
    "        Create one long numpy array from all the tile’s labels of every given dem map.\n",
    "        '''\n",
    "         \n",
    "        all_magnitudes_np = np.concatenate([d.fft_magnitude_all_levels for d in instances], axis = 0)\n",
    "\n",
    "        # Normalize across all DEMs\n",
    "        all_magnitudes_np = (all_magnitudes_np - np.median(all_magnitudes_np, axis = 0, keepdims = True)) / np.std(all_magnitudes_np, axis = 0, keepdims = True)\n",
    "\n",
    "        # Store the original sizes to late split the labels again\n",
    "        original_tile_count = [d.fft_magnitude_all_levels.shape[0] for d in instances]\n",
    "        original_indices_for_splitting = np.cumsum(original_tile_count[:-1])\n",
    "\n",
    "        # Clustering section\n",
    "        n_clusters = cls.settings[\"output\"][\"label_count\"]\n",
    "        k_means_clusterer = KMeans(n_clusters = n_clusters, random_state = 550)\n",
    "\n",
    "\n",
    "        with SimpleTimer(\"Clustering\"):\n",
    "                all_magnitudes_np = np.nan_to_num(all_magnitudes_np, nan = 0)\n",
    "                all_dem_labels = k_means_clusterer.fit_predict(all_magnitudes_np)\n",
    "\n",
    "        with SimpleTimer(\"Relabeling Cluster IDs by size\"):\n",
    "                all_dem_labels = sort_labels(all_dem_labels)\n",
    "\n",
    "        # Distribute the results back to the augmented dem objects\n",
    "        single_dem_lables = np.split(all_dem_labels, original_indices_for_splitting) \n",
    "\n",
    "        for i, labels in enumerate(single_dem_lables):\n",
    "            instances[i].labels = labels\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c33c9b5",
   "metadata": {},
   "source": [
    "## Code explanation: This is the core of the project\n",
    "\n",
    "The **AugmentedDem Class** is where most of the processing takes place.\n",
    "Each instance corresponds to a GeoTIFF (that can be downloaded via the seccondary notebook).\n",
    "\n",
    "### What it stores\n",
    "It stores general information that is read from the GeoTIFF file. Namely it’s bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e3596b",
   "metadata": {},
   "source": [
    "<a id = \"execution\">Anchor</a>\n",
    "\n",
    "## Code explanation: Processing pipeline\n",
    "\n",
    "The following cell executes all of the processing.\n",
    "Settings are set at the [top of the notebook](#settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a place for the newly made calculations\n",
    "temporary_data = {}\n",
    "temporary_data[\"augmented_dems\"] = []\n",
    "\n",
    "\n",
    "# Assign the settings to the class variable of AugmentedDem\n",
    "AugmentedDEM.settings = internal_settings\n",
    "\n",
    "\n",
    "# Create objects (AugmentedDem) for all .tif-Files inside the dem_folder\n",
    "with os.scandir(internal_settings[\"files\"][\"dem_folder\"]) as dirlist:\n",
    "    temporary_data[\"augmented_dems\"] = [AugmentedDEM(d.path) \n",
    "                                        for d in dirlist if re.search(r\"\\.tif$\",d.name)]\n",
    "    \n",
    "\n",
    "# Set up the masks for the weighted average\n",
    "with VerboseInfoTimer(\"Creating the ring masks\"):\n",
    "    temporary_data[\"circle_masks\"] = RingImageSeries(internal_settings[\"fft\"][\"tile_size_px\"],\n",
    "                                                        internal_settings[\"fft\"][\"tile_size_px\"],\n",
    "                                                        internal_settings[\"fft\"][\"fft_levels\"],\n",
    "                                                        bandwidth = 1)\n",
    "\n",
    "\n",
    "# This is the main processing. Here the \"FFT\" footprints are created\n",
    "for i, d in enumerate(temporary_data[\"augmented_dems\"]):\n",
    "    with VerboseInfoTimer(\"Processing of all DEM maps\", \n",
    "                    current_index = i, \n",
    "                    total_count = len(temporary_data[\"augmented_dems\"]),\n",
    "                    single_description = \"Processing DEM map\"):\n",
    "        d.process_dem_fast()\n",
    "\n",
    "\n",
    "# Create_labels(temporary_data[\"augmented_dems\"], internal_settings)\n",
    "with VerboseInfoTimer(\"Clustering and creating labels for all DEM maps\"):\n",
    "    AugmentedDEM.create_labels(temporary_data[\"augmented_dems\"])\n",
    "\n",
    "\n",
    "# Using the labels created across all DEMs we calculate the resulting maps for each individual dem map\n",
    "for i, d in enumerate(temporary_data[\"augmented_dems\"]):\n",
    "    with VerboseInfoTimer(\"Creating labeled images for all regions\", \n",
    "                    current_index = i, \n",
    "                    total_count = len(temporary_data[\"augmented_dems\"]),\n",
    "                    single_description = \"Creating labeled image\"):\n",
    "        d.create_image()\n",
    "        d.write_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3726fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Testing\n",
    "    import cartopy.crs as ccrs\n",
    "    import cartopy.feature as cfeature\n",
    "\n",
    "    current_augmented_dem = temporary_data[\"augmented_dems\"][0]\n",
    "    image = np.transpose(current_augmented_dem.image_rgb,[1,2,0])\n",
    "\n",
    "    west, south, east, north = current_augmented_dem.geo_bounds.as_list()\n",
    "    extent = (west, east, south, north)\n",
    "\n",
    "    # Start plotting\n",
    "    fig = plt.figure(figsize = (10, 15), dpi = 256)\n",
    "    ax = plt.axes(projection = ccrs.Orthographic(central_longitude = current_augmented_dem.geo_bounds.center_x, central_latitude = current_augmented_dem.geo_bounds.center_y))\n",
    "\n",
    "    ax.set_extent(extent)\n",
    "\n",
    "    # Add features\n",
    "    ax.add_feature(cfeature.BORDERS, edgecolor = \"black\", linewidth = 0.5)\n",
    "    ax.add_feature(cfeature.COASTLINE, edgecolor = \"white\", linewidth = 1.0)\n",
    "    ax.add_feature(cfeature.LAKES, edgecolor = 'black', facecolor = 'none')\n",
    "    ax.add_feature(cfeature.RIVERS, edgecolor = 'blue', linewidth = 0.3)\n",
    "    ax.add_feature(cfeature.OCEAN, zorder = 1, facecolor = '#102d2d')\n",
    "\n",
    "    # Plot image (projecting from PlateCarree, which assumes lat/lon coordinates)\n",
    "    ax.imshow(image, origin = 'upper', extent = extent, transform = ccrs.PlateCarree())\n",
    "\n",
    "    # Optionally, add gridlines\n",
    "    ax.gridlines(draw_labels = True, linewidth = 0.2)\n",
    "\n",
    "    # Show\n",
    "    plt.title(f\"Colored landscape clusters for {os.path.basename(current_augmented_dem.dem_path)}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a1ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
