{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27f751b4",
   "metadata": {},
   "source": [
    "# Primary Notebook\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The purpose of this notebook is the creation of the clusters.\n",
    "Those (landscape) clusters are supposed to be areas similar in appearance;\n",
    "To be more precise, these clusters share a common \"FFT footprint\" which will be elaborated on later.\n",
    "\n",
    "## Other parts of this project\n",
    "\n",
    "There are secondary notebooks, that might have to be run beforehand, to receive data which this primary notebook will work upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a574dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we might need eventually\n",
    "# rasterio for geotiffs\n",
    "# dask array for parallel computing of large arrays\n",
    "# pyfftw for 2d fft "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2bb14b",
   "metadata": {},
   "source": [
    "## Overview of the classes and their interconnection\n",
    "The subject of this notebook is to cluster different landscapes across multiple DEM-GeoTIFFs. \n",
    "\n",
    "### GeographicBounds\n",
    "This is an object that saves West, South, East, North borders, as well as the projection, and maybe some other additional info.\n",
    "\n",
    "### AugmentedDEM\n",
    "This will be the \"container\" for all information regarding *one* specific DEM raster map.\n",
    "\n",
    "### EmbeddingMap\n",
    "This will be part of each AugmentedDEM. Here we will save the labels created by the clustering.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485369e7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc9a77bc",
   "metadata": {},
   "source": [
    "## How to make the GeoTIFF images usable by my algorithm:\n",
    "It’s important to note, that the original DEM data is in arc seconds. To avoid skewed results it has to be compressed by cos(latitude) in width.  That way the metric distances (almost) resemble the distances pixel-wise\n",
    "\n",
    "After that the images will be scaled to 1/4 (as of now), because processing becomes about 4^2 times faster.\n",
    "\n",
    "Before processing, the data will have to be split up into quadratic tiles which are supposed to be equal in their length.\n",
    "\n",
    "I guess we should combine the processes, namely selecting tiles of equal size and then reducing their size to a given size in pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7eaa0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Filesystem, JSON\n",
    "import os\n",
    "import json\n",
    "from io import BytesIO # To be able to route the API response to a file-like object that rasterio can use\n",
    "\n",
    "# Rasterio for handling GeoTIFFs\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "from rasterio.windows import from_bounds\n",
    "\n",
    "# Resampling of the tiles\n",
    "from PIL import Image \n",
    "\n",
    "# For interpolation of the results\n",
    "from scipy.interpolate import griddata\n",
    "from scipy import ndimage # for filtering\n",
    " \n",
    "\n",
    "# Math may not be missing\n",
    "import math\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import pyfftw \n",
    "\n",
    "# The heart: we use k-means-clustering\n",
    "from sklearn.cluster import KMeans\n",
    "import hdbscan\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Regex for updating filenames\n",
    "import re\n",
    "\n",
    "# For earth related numbers\n",
    "from pyproj import Geod\n",
    "geod = Geod(ellps=\"WGS84\")\n",
    "\n",
    "# Matplotlib for checks\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "# For timing \n",
    "import time\n",
    "\n",
    "# For multiprocessing\n",
    "from multiprocess import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "782e7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTimer:\n",
    "    '''This class is just a timer for checking the performance'''\n",
    "    def __init__(self, description):\n",
    "        self.description = description\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.timer = time.perf_counter()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.time_needed = time.perf_counter() - self.timer\n",
    "        print(f\"{self.description} took {self.time_needed:.1f} Seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ddca61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for running this Notebook\n",
    "\n",
    "internal_settings = {}\n",
    "\n",
    "internal_settings[\"files\"] = {}\n",
    "internal_settings[\"files\"][\"dem_folder\"] = \"geotiffs\" #Here the to-be-used-geotiffs are located\n",
    "\n",
    "internal_settings[\"fft\"] = {}\n",
    "internal_settings[\"fft\"][\"tile_size_km\"] = 10 #average length and width of a tile that is processed individually\n",
    "internal_settings[\"fft\"][\"tile_size_px\"] = 20\n",
    "\n",
    "internal_settings[\"fft\"][\"tile_overlap_percent\"] = 85 # How much (by a tile length in percent) do the tiles overlap\n",
    "internal_settings[\"fft\"][\"tile_overlap_multi\"] =  1 / (1 - (internal_settings[\"fft\"][\"tile_overlap_percent\"]/100))\n",
    "internal_settings[\"fft\"][\"fft_levels\"] = 12  \n",
    "\n",
    "internal_settings[\"output\"] = {}\n",
    "internal_settings[\"output\"][\"label_mode_filter_radius\"] = 15  \n",
    "internal_settings[\"output\"][\"label_count\"] = 7  \n",
    "internal_settings[\"output\"][\"q_factor\"] = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "570cb460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiprocessing stuff\n",
    "def init_worker(image_array, transform, tile_size):\n",
    "            global shared_image_array, shared_transform, shared_tile_size\n",
    "            shared_image_array, shared_transform, shared_tile_size = image_array, transform, tile_size\n",
    "\n",
    "def resample_tile(bounds):\n",
    "    global shared_image_array, shared_transform, shared_tile_size\n",
    "\n",
    "    source_window = from_bounds(*bounds, transform=shared_transform)\n",
    "\n",
    "    # Round the resulting window to actual pixels to be used as indices\n",
    "    window_row_off_px = int(source_window.row_off)\n",
    "    window_col_off_px = int(source_window.col_off)\n",
    "    window_height_px = int(source_window.height)\n",
    "    window_width_px = int(source_window.width)\n",
    "\n",
    "    # Create a tile as an np array from the original raster image using the given bounds\n",
    "    # First index is for different channels!\n",
    "    tile = shared_image_array[:, window_row_off_px : window_row_off_px + window_height_px,\n",
    "                            window_col_off_px : window_col_off_px + window_width_px]\n",
    "    \n",
    "    tile_resampled = np.stack([\n",
    "        np.array(Image.fromarray(channel).resize((shared_tile_size, shared_tile_size), resample=Image.BILINEAR)) for channel in tile\n",
    "    ])\n",
    "\n",
    "    return tile_resampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2545343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort labels by size\n",
    "\n",
    "def sort_labels(labels):\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    size_order = np.argsort(-counts)\n",
    "\n",
    "    lookup = np.empty_like(unique)\n",
    "    lookup[size_order] = np.arange(len(size_order))\n",
    "\n",
    "    relabeled = lookup[labels]\n",
    "    return relabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cfba279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes specific to this project \n",
    "\n",
    "# This class is supposed to store coordinates for tiles and maybe coordinate systems in the future\n",
    "class GeographicBounds:\n",
    "    def __init__(self, west, south, east, north):\n",
    "        self.west = west\n",
    "        self.north = north\n",
    "        self.east = east\n",
    "        self.south = south\n",
    "\n",
    "    @property\n",
    "    def center_x (self): # Center longitude\n",
    "        return (self.west+self.east)/2\n",
    "\n",
    "    @property\n",
    "    def center_y (self): # Center latitude\n",
    "        return (self.north+self.south)/2\n",
    "    \n",
    "    @property\n",
    "    def center_combined (self): # Center latitude\n",
    "        return (self.center_y, self.center_x)\n",
    "\n",
    "    @property\n",
    "    def height_degrees (self): # Height in kilometres\n",
    "        return (abs(self.south - self.north))\n",
    "\n",
    "    @property\n",
    "    def width_degrees (self): # Height in kilometres\n",
    "        return min (abs(self.east - self.west), 360 - abs(self.east - self.west));  #when getting to ±180° it should choose the shorter width # CAUTION, this might be not the final solution\n",
    "\n",
    "    @property\n",
    "    def height_km (self): # Height in kilometres\n",
    "        return (abs(self.south - self.north) / 360.0) * math.pi * 2.0 * geod.b / 1000.0\n",
    "   \n",
    "    @property\n",
    "    def width_north_km (self): # North width in kilometres\n",
    "        return (abs(self.west - self.east) / 360.0) * math.pi * 2.0 * geod.a * math.cos( math.radians(self.north) ) / 1000.0 \n",
    "   \n",
    "    @property\n",
    "    def width_south_km (self): # North width in kilometres\n",
    "        return (abs(self.west - self.east) / 360.0) * math.pi * 2.0 * geod.a * math.cos( math.radians(self.south) ) / 1000.0 \n",
    "\n",
    "    # Return information about the object (for to be used in a print statement for example)\n",
    "    def __str__(self):\n",
    "        infostring = \"Infos about the GeographicBounds (all rounded):\\n\"\n",
    "        infostring += f\"-----\\n\"\n",
    "        infostring += f\"Geographic Bounds:\\n\"\n",
    "        infostring += f\"West: {self.west:>8.2f}° \\n\"\n",
    "        infostring += f\"South: {self.south:>7.2f}° \\n\"\n",
    "        infostring += f\"East: {self.east:>8.2f}° \\n\"\n",
    "        infostring += f\"North: {self.north:>7.2f}\\n\"\n",
    "        infostring += f\"-----\\n\"\n",
    "        infostring += f\"Northern Width: {self.width_north_km:.2f} km\\n\"\n",
    "        infostring += f\"Southern Width: {self.width_south_km:.2f} km\\n\"\n",
    "        infostring += f\"Height: {self.height_km:.2f} km\\n\"\n",
    "        infostring += f\"-----\\n\"\n",
    "        infostring += f\"Center (lon E, lat N): {self.center_y:.3f}°, {self.center_x:.3f}°\\n\"\n",
    "        infostring += \"\\n\"\n",
    "        return infostring\n",
    "    \n",
    "    def as_list(self):\n",
    "        return [self.west, self.south, self.east, self.north]\n",
    "    \n",
    "    def as_list_rearranged(self):\n",
    "        return [self.west, self.north, self.east, self.south]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b5496a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def ModeFilterLabels(label_map, radius = 10):\n",
    "        y, x = np.ogrid[-radius:radius+1, -radius:radius+1]\n",
    "        mask = x**2 + y**2 <= radius **2\n",
    "        \n",
    "\n",
    "        def mode_filter_func(values):\n",
    "            counts = np.bincount(values.astype(\"uint8\"))\n",
    "            return np.argmax(counts)\n",
    "        \n",
    "        filtered = ndimage.generic_filter(\n",
    "            label_map,\n",
    "            function = mode_filter_func,\n",
    "            footprint=mask,\n",
    "            mode=\"nearest\"\n",
    "        )\n",
    "\n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fee8f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This class will contain information about each geotiff that is used for the fft calculations\n",
    "class AugmentedDEM:\n",
    "    def __init__(self, dem_path, settings):\n",
    "        self.settings = settings\n",
    "        with rasterio.open(dem_path) as dem_file:\n",
    "            self.geo_bounds = GeographicBounds(dem_file.bounds.left, \n",
    "                                               dem_file.bounds.bottom,\n",
    "                                               dem_file.bounds.right,\n",
    "                                               dem_file.bounds.top)\n",
    "            self.dem_width_px = dem_file.width\n",
    "            self.dem_height_px = dem_file.height\n",
    "        self.dem_path = dem_path\n",
    "        \n",
    "\n",
    "\n",
    "    def _calculate_tile_bounds(self): # alternative implementation that gives back the borders and stuff in degrees\n",
    "        # Height of a tile in degrees\n",
    "        \n",
    "        # Squeeze more tiles in\n",
    "        tilemulti = self.settings[\"fft\"][\"tile_overlap_multi\"]\n",
    "\n",
    "        tile_height_degrees = 360 * self.settings[\"fft\"][\"tile_size_km\"] * 1000 /  (math.pi * 2.0 * geod.b)\n",
    "\n",
    "        relative_start_y = (self.geo_bounds.height_degrees % tile_height_degrees) / 2\n",
    "        absolute_start_y = (self.geo_bounds.north - relative_start_y)\n",
    "        absolute_end_y = (self.geo_bounds.south + relative_start_y)\n",
    "        number_tiles_y = int((self.geo_bounds.height_degrees // tile_height_degrees)*tilemulti)\n",
    "\n",
    "        absolute_borders_y = np.linspace(absolute_start_y, absolute_end_y, number_tiles_y + 1 )\n",
    "        absolute_centers_y = np.linspace(absolute_start_y - (tile_height_degrees / 2), absolute_end_y + (tile_height_degrees / 2), number_tiles_y )\n",
    "\n",
    "\n",
    "        # Here will go the X-splitting. X will be split with a different tile_width_degrees for each centers_y\n",
    "        # That is due to the fact that x inside a sector of the earth’s surface is getting smaller in direction of the poles (cos)\n",
    "        # This is why this is a list of np.arrays and not a 2D np-array (as length varies for each row!)\n",
    "\n",
    "        absolute_borders_x = []\n",
    "        self.tile_bounds = []\n",
    "\n",
    "        \n",
    "        for i, center_y in enumerate(absolute_centers_y):\n",
    "            tile_width_degrees = 360 * self.settings[\"fft\"][\"tile_size_km\"] * 1000 /  (math.pi * 2.0 * geod.a)  / math.cos (math.radians(center_y))\n",
    "            \n",
    "            relative_start_x = (self.geo_bounds.width_degrees % tile_width_degrees) / 2\n",
    "            absolute_start_x = (self.geo_bounds.west + relative_start_x)\n",
    "            absolute_end_x = (self.geo_bounds.east - relative_start_x)\n",
    "            number_tiles_x = int((self.geo_bounds.width_degrees // tile_width_degrees)*tilemulti)\n",
    "\n",
    "            tmp_absolute_borders_x = np.linspace(absolute_start_x, absolute_end_x, number_tiles_x + 1 )\n",
    "            tmp_absolute_centers_x = np.linspace(absolute_start_x + (tile_width_degrees / 2), absolute_end_x - (tile_width_degrees / 2), number_tiles_x)\n",
    "\n",
    "            absolute_borders_x.append( np.array(tmp_absolute_borders_x) )\n",
    "\n",
    "        \n",
    "        for y in range(len(absolute_centers_y-1)):\n",
    "            for x in range(len(absolute_borders_x[y])-1):\n",
    "                self.tile_bounds.append(\n",
    "                    GeographicBounds(absolute_borders_x[y][x],\n",
    "                                    absolute_borders_y[y],\n",
    "                                    absolute_borders_x[y][x+1],\n",
    "                                    absolute_borders_y[y+1]))\n",
    "                \n",
    "    def _resample_tiles_old(self):\n",
    "        '''This method resamples tiles from the original dem data\n",
    "        The tiles all have the same pixel dimensions.\n",
    "        This approach takes forever.\n",
    "        Could be improved by resampling rows instead of tiles and then slicing them'''\n",
    "\n",
    "\n",
    "        with SimpleTimer(\"Resampling the Tiles\"):\n",
    "            with rasterio.open(self.dem_path) as source:\n",
    "                tile_bounds_np = np.array([bnd.as_list() for bnd in self.tile_bounds])\n",
    "                num_tiles = len(tile_bounds_np)\n",
    "                self.tiles_resampled = np.empty((num_tiles, \n",
    "                                self.settings[\"fft\"][\"tile_size_px\"], \n",
    "                                self.settings[\"fft\"][\"tile_size_px\"]), dtype = source.dtypes[0])\n",
    "\n",
    "                for i, bound in enumerate(tile_bounds_np):\n",
    "                    src_window = from_bounds(bound[0], bound[3], bound[2], bound[1], source.transform) \n",
    "                    tile_resampled = source.read(\n",
    "                        out_shape = (source.count, \n",
    "                                    self.settings[\"fft\"][\"tile_size_px\"], \n",
    "                                    self.settings[\"fft\"][\"tile_size_px\"]),\n",
    "                                    window = src_window,\n",
    "                                    resampling = rasterio.enums.Resampling.cubic\n",
    "                    )\n",
    "\n",
    "                    # Remove erroneous values\n",
    "                    self.tiles_resampled = np.nan_to_num(self.tiles_resampled, nan = 0)\n",
    "\n",
    "                    # Remove height from the landscape by substracting the median\n",
    "                    self.tiles_resampled = self.tiles_resampled - np.mean(self.tiles_resampled, axis = (1,2), keepdims=True)\n",
    "\n",
    "                    self.tiles_resampled[i] = tile_resampled\n",
    "\n",
    "\n",
    "\n",
    "    def _resample_tiles_multiprocessing(self):\n",
    "        '''This method resamples tiles from the original dem data\n",
    "        to all have the same pixel dimensions.'''\n",
    "    \n",
    "        tile_size = self.settings[\"fft\"][\"tile_size_px\"]\n",
    "\n",
    "        with SimpleTimer(\"Multiprocessing Resample of Tiles\"):\n",
    "         \n",
    "            \n",
    "            with rasterio.open(self.dem_path) as source_image:\n",
    "                full_image_array = source_image.read()\n",
    "                transform = source_image.transform\n",
    "            \n",
    "            tile_bounds_list = [bnd.as_list_rearranged() for bnd in self.tile_bounds]\n",
    "\n",
    "            with Pool(processes=cpu_count(),\n",
    "                    initializer=init_worker,\n",
    "                    initargs=(full_image_array, transform, tile_size)) as pool:\n",
    "                self.tiles_resampled = np.array(pool.map(resample_tile, tile_bounds_list))\n",
    "                self.tiles_resampled = np.squeeze(self.tiles_resampled, axis = 1) # remove the dimension for the channels, as in DEM data there should only be one channel\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def dump_tiles(self):\n",
    "        '''This method writes the resampled tiles to disk, just for checking'''\n",
    "        for i, tile in enumerate(self.tiles_resampled):\n",
    "            height = self.settings[\"fft\"][\"tile_size_px\"]\n",
    "            width = self.settings[\"fft\"][\"tile_size_px\"]\n",
    "\n",
    "            # Calculate pixel resolution (degrees per pixel)\n",
    "            res_x = ((self.tile_bounds[i].east - self.tile_bounds[i].west) / width)\n",
    "            res_y = ((self.tile_bounds[i].north - self.tile_bounds[i].south) / height)\n",
    "\n",
    "            # Create affine transform (pixel coordinates → WGS84)\n",
    "            transform = Affine.translation(self.tile_bounds[i].west, self.tile_bounds[i].south) * Affine.scale(res_x, res_y)\n",
    "\n",
    "            filepath = f\"tile_dump/{self.tile_bounds[i].west:.3f}_{self.tile_bounds[i].north:.3f}.tif\"\n",
    "\n",
    "            # Write GeoTIFF\n",
    "            with rasterio.open(\n",
    "                filepath,\n",
    "                \"w\",\n",
    "                driver=\"GTiff\",\n",
    "                height=height,\n",
    "                width=width,\n",
    "                count=1, \n",
    "                dtype=tile.dtype,\n",
    "                crs=\"EPSG:4326\", \n",
    "                transform=transform,\n",
    "            ) as dst:\n",
    "                dst.write(tile[np.newaxis,:])\n",
    "\n",
    "\n",
    "\n",
    "    def _create_fft_tiles(self):\n",
    "        with SimpleTimer(\"Creating FFT footprints\"):\n",
    "            fft_input_array = pyfftw.empty_aligned((len(self.tiles_resampled),\n",
    "                                                    self.settings[\"fft\"][\"tile_size_px\"],\n",
    "                                                    self.settings[\"fft\"][\"tile_size_px\"]),\n",
    "                                                    dtype = \"complex64\")\n",
    "\n",
    "            fft_output_array =  pyfftw.empty_aligned((len(self.tiles_resampled),\n",
    "                                                    self.settings[\"fft\"][\"tile_size_px\"],\n",
    "                                                    self.settings[\"fft\"][\"tile_size_px\"]),\n",
    "                                                    dtype = \"complex64\")\n",
    "\n",
    "            fft_execution_plan = pyfftw.FFTW(fft_input_array,\n",
    "                                            fft_output_array, axes=(1,2),\n",
    "                                            direction=\"FFTW_FORWARD\",\n",
    "                                            flags=(\"FFTW_MEASURE\",))\n",
    "\n",
    "            fft_input_array[:] = self.tiles_resampled #Important. [:] ensures the reserved empty array is used, and no new one is created! It will not work without that special slicing.\n",
    "\n",
    "            fft_execution_plan.execute()\n",
    "\n",
    "            fft_magnitude_spectra_unshifted = np.log(np.abs(fft_output_array) + 1) \n",
    "            self.fft_footprint = np.fft.fftshift(fft_magnitude_spectra_unshifted, axes=(1,2)) #Centered FFT\n",
    "\n",
    "\n",
    "\n",
    "    def _split_and_average_fft_tiles(self):\n",
    "        # Set up Dask Arrays for faster computation of the weighted averages\n",
    "\n",
    "\n",
    "        # The general dimensions are:\n",
    "        # 1. Number of tiles (total)\n",
    "        # 2. Height of a tile\n",
    "        # 3. Width of a tile\n",
    "        # 4. Number of levels (circle filters)\n",
    "\n",
    "        # To multiply and divide all the dimensions have to be in the same order for all arrays\n",
    "\n",
    "        # Weights – here go the circles\n",
    "        # Weights are still (#4, #2, #3), change them to #2, #3, #4\n",
    "\n",
    "\n",
    "        with SimpleTimer(\"Creating the weighted averages per mask\"):\n",
    "            da_weights = da.from_array(\n",
    "                # The height becomes axis 0, width becomes axis 1, and different masks become axis 2\n",
    "                np.transpose(temporary_settings[\"circle_masks\"],(1,2,0)) \n",
    "            )\n",
    "\n",
    "            # First dimension (#1) is missing, add it \n",
    "            # Just a note: the tiles themselves are not x-y adressed, but the get a continuous index (1D)\n",
    "            da_weights = da_weights[np.newaxis, ...]\n",
    "            # Now the form of the weights is (#1, #2, #3, #4) like explained above\n",
    "\n",
    "            # Take the results of the fft and place them also in a dask array\n",
    "            # of the wanted form (see above) \n",
    "            da_magnitude_spectra = da.from_array(self.fft_footprint)[...,np.newaxis]\n",
    "\n",
    "            # Sum the values of the areas covered by the circles, to later have something to divide by\n",
    "            # to generate weighted sums\n",
    "            da_weights_sum = da.sum(da_weights, axis=(1,2)) \n",
    "\n",
    "            # Sum the results of the FFTs multiplied by the weights of the different levels (circle filters)\n",
    "            da_sum_of_spectra = da.sum(da_magnitude_spectra * da_weights, axis=(1, 2))\n",
    "\n",
    "            # Calculate the weighted average \n",
    "            da_weighted_averages = da_sum_of_spectra / da_weights_sum\n",
    "\n",
    "            # The result is now in the shape of #1, #4 -> Number of Tiles, Number of Levels\n",
    "            self.fft_magnitude_all_levels = da_weighted_averages.compute() \n",
    "\n",
    "\n",
    "    def _normalize_fft_averages(self):\n",
    "        '''lower_quartile = np.quantile(self.fft_magnitude_all_levels,0.25, axis=0, keepdims=True)\n",
    "        upper_quartile = np.quantile(self.fft_magnitude_all_levels,0.75, axis=0, keepdims=True)\n",
    "        interquartile_range = upper_quartile - lower_quartile\n",
    "\n",
    "        self.fft_magnitude_all_levels = ((self.fft_magnitude_all_levels - lower_quartile) / interquartile_range)'''\n",
    "\n",
    "        self.fft_magnitude_all_levels = (self.fft_magnitude_all_levels - np.median(self.fft_magnitude_all_levels, axis=0, keepdims=True)) / np.std(self.fft_magnitude_all_levels, axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "\n",
    "    def _create_labels(self):\n",
    "        # Set up clustering, we stick with kmeans as it is damn fast\n",
    "        n_clusters = self.settings[\"output\"][\"label_count\"]\n",
    "        min_cluster_size = int(self.fft_magnitude_all_levels.shape[0]*0.00010) +2 \n",
    "\n",
    "        k_means_clusterer = KMeans(n_clusters = n_clusters, random_state=550)\n",
    "        hdb_clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "        optics_clusterer = OPTICS(min_samples=min_cluster_size)\n",
    "        meanshift_clusterer = MeanShift()\n",
    "        dbscan_clusterer = DBSCAN(eps=0.9, min_samples=min_cluster_size)\n",
    "\n",
    "        # Cluster it (this is the peak of the process)\n",
    "        with SimpleTimer(\"Clustering\"):\n",
    "            self.labels = k_means_clusterer.fit_predict(self.fft_magnitude_all_levels)\n",
    "            # self.labels = hdb_clusterer.fit_predict(self.fft_magnitude_all_levels)\n",
    "            # self.labels = optics_clusterer.fit_predict(self.fft_magnitude_all_levels) # Shit results\n",
    "            # self.labels = meanshift_clusterer.fit_predict(self.fft_magnitude_all_levels) # VERY VERY SLOW\n",
    "            # self.labels = dbscan_clusterer.fit_predict(self.fft_magnitude_all_levels) # varying results\n",
    "            \n",
    "        # To compare different settings visually, it is important to\n",
    "        # always have the clusters in the same order approximately\n",
    "        with SimpleTimer(\"Sorting Clusters\"):\n",
    "            self.labels = sort_labels(self.labels)\n",
    "\n",
    "       \n",
    "    def _create_image(self):\n",
    "        # This is a rewrite of the CreateImage function.\n",
    "        # There was a design error before, the data was interpolated before it was clustered\n",
    "        # That led to massive cluster computations that are completely unnecessary\n",
    "        # We will cluster first, then interpolate\n",
    "\n",
    "        # Interpolate the found clusters to an image\n",
    "        tmp_tile_positions = [tile.center_combined for tile in self.tile_bounds]\n",
    "        tmp_pic_width = self.dem_width_px // self.settings[\"output\"][\"q_factor\"]\n",
    "        tmp_pic_height = self.dem_height_px // self.settings[\"output\"][\"q_factor\"]\n",
    "\n",
    "        tmp_grid_res_y = np.linspace(self.geo_bounds.north, self.geo_bounds.south, tmp_pic_height )\n",
    "        tmp_grid_res_x = np.linspace(self.geo_bounds.west, self.geo_bounds.east, tmp_pic_width )\n",
    "\n",
    "        tmp_grid_y, tmp_grid_x = np.meshgrid(tmp_grid_res_y, tmp_grid_res_x, indexing=\"ij\")\n",
    "\n",
    "        tmp_interpolated = griddata(tmp_tile_positions,\n",
    "        self.labels, (tmp_grid_y, tmp_grid_x), method='nearest') \n",
    "\n",
    "        print(tmp_interpolated.shape)        \n",
    "\n",
    "        with SimpleTimer(\"Filtering of the mapped labels\"):\n",
    "            tmp_interpolated = ModeFilterLabels(tmp_interpolated, self.settings[\"output\"][\"label_mode_filter_radius\"])\n",
    "\n",
    "        # Important: when using anything else, arbitrary labels will be created (1.2142 instead of 1)\n",
    "        # Labels cannot be interpolated\n",
    "\n",
    "\n",
    "        # start creating the image\n",
    "   \n",
    "        # Calculate pixel resolution (degrees per pixel)\n",
    "        res_x = ((self.geo_bounds.east - self.geo_bounds.west) / tmp_pic_width)\n",
    "        res_y = ((self.geo_bounds.south - self.geo_bounds.north) / tmp_pic_height)\n",
    "\n",
    "        # Create affine transform (pixel coordinates → WGS84)\n",
    "        transform = Affine.translation(self.geo_bounds.west,\n",
    "                                    self.geo_bounds.north) * Affine.scale(res_x, res_y)\n",
    "\n",
    "\n",
    "        cmap = plt.get_cmap(\"viridis\")\n",
    "\n",
    "        normalizer = colors.Normalize(vmin=tmp_interpolated.min(), vmax=tmp_interpolated.max())\n",
    "        tmp_interpolated = normalizer(tmp_interpolated)\n",
    "\n",
    "\n",
    "        tmp_labels_image_rgb = cmap(tmp_interpolated)\n",
    "\n",
    "        print(tmp_labels_image_rgb.shape)\n",
    "\n",
    "        tmp_labels_image_rgb = (np.transpose(tmp_labels_image_rgb[...,:3], (2,0,1))*256).astype(\"uint8\")\n",
    "\n",
    "        filename_string = f\"test_result \" + \\\n",
    "        f\"tlszkm {self.settings[\"fft\"][\"tile_size_km\"]:.1f}  \" + \\\n",
    "        f\"tlszpx {self.settings[\"fft\"][\"tile_size_px\"]:.0f}  \" + \\\n",
    "        f\"fftlvls {self.settings[\"fft\"][\"fft_levels\"]:.0f}  \" + \\\n",
    "        f\"qfctr {self.settings[\"output\"][\"q_factor\"]:.0f}  \" + \\\n",
    "        f\"{self.settings[\"fft\"][\"tile_overlap_multi\"]:.1f}x\"+ \\\n",
    "        f\"-ovrlp-pct {self.settings[\"fft\"][\"tile_overlap_percent\"]:.0f} \"+ \\\n",
    "        f\"fltrrds {self.settings[\"output\"][\"label_mode_filter_radius\"]:.0f} \"+ \\\n",
    "        f\".tif\"\n",
    "\n",
    "        # Write GeoTIFF\n",
    "        with rasterio.open(\n",
    "            filename_string,\n",
    "            \"w\",\n",
    "            driver=\"GTiff\",\n",
    "            height=tmp_pic_height,\n",
    "            width=tmp_pic_width,\n",
    "            count=3, \n",
    "            dtype=\"uint8\",\n",
    "            crs=\"EPSG:4326\", \n",
    "            transform=transform,\n",
    "        ) as dst:\n",
    "            dst.write(tmp_labels_image_rgb[0],1)\n",
    "            dst.write(tmp_labels_image_rgb[1],2)\n",
    "            dst.write(tmp_labels_image_rgb[2],3)\n",
    "\n",
    "\n",
    "    def process_dem(self):\n",
    "        self._calculate_tile_bounds()\n",
    "        self._resample_tiles_multiprocessing()\n",
    "        self._create_fft_tiles()\n",
    "        self._split_and_average_fft_tiles()\n",
    "        self._normalize_fft_averages()\n",
    "        self._create_labels()\n",
    "        self._create_image()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "646078e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Euclidean (y_a, y_b, x_a, x_b):\n",
    "    return math.sqrt((y_a-y_b)**2 + (x_a-x_b)**2)\n",
    "\n",
    "def Threshold (input, threshold, bandwidth = 1):\n",
    "    # This ist just for anti aliasing the circle mask\n",
    "    # The input is claped to the bandwidth\n",
    "    result = np.interp(input, [threshold-(bandwidth/2), threshold+(bandwidth/2)], [0,1])\n",
    "    return result;\n",
    "\n",
    "\n",
    "def CircleImage (height, width, radius, inverted = False, bandwidth = 1):\n",
    "    # Returns the image of a circle as a numpy array for masking\n",
    "    # The bandwidth defines the width of the border of the circle (for anti aliasing)\n",
    "\n",
    "    circle_image = np.zeros((height, width))\n",
    "\n",
    "    if radius == 0:\n",
    "        return (1 - circle_image) if inverted else (circle_image)\n",
    "    else:\n",
    "        for x in range(width):\n",
    "            for y in range(height):\n",
    "                circle_image[y,x] = Euclidean(\n",
    "                    y+(0.5 if height%2 == 1 else 0), height / 2,\n",
    "                    x+(0.5 if width%2 == 1 else 0), width / 2\n",
    "                )\n",
    "\n",
    "    if inverted:\n",
    "        return 1-Threshold(circle_image, radius, 1)\n",
    "    else:\n",
    "        return Threshold(circle_image, radius, 1)\n",
    "\n",
    "def RingImage (height, width, inner_radius, outer_radius, bandwidth):\n",
    "    if outer_radius < inner_radius:\n",
    "        raise ValueError(\"The inner radius must be smaller than the outer radius.\")\n",
    "\n",
    "    # This combines two circles to form a ring mask\n",
    "    outercircle = CircleImage(height, width, outer_radius, \n",
    "                              inverted = True, bandwidth=bandwidth)\n",
    "    innercircle = CircleImage(height, width, inner_radius, \n",
    "                              inverted = True, bandwidth=bandwidth)\n",
    "    \n",
    "    ringimg = outercircle - innercircle\n",
    "\n",
    "    return  (ringimg - ringimg.min()) / (ringimg.max() - ringimg.min())\n",
    "\n",
    "def RingImageSeries(height,width,steps,bandwidth):\n",
    "    '''This creates a 3D numpy array of the shape\n",
    "    (Masks, individual Height, individual Width)\n",
    "    This is used to sum and average the FFT magnitudes'''\n",
    "\n",
    "    with SimpleTimer(\"Creating the ring masks\"):\n",
    "        # The diameter gets bigger logarithmically, starting with a diameter of 1\n",
    "        smallest_side = min(height,width)\n",
    "\n",
    "        outer_radii = np.logspace(0, np.log2(smallest_side / 2), steps, base=2) # 0 means it starts with 1 (log)\n",
    "        inner_radii = np.append(0,outer_radii[:-1])\n",
    "\n",
    "\n",
    "        all_masks = np.zeros((steps,height, width))\n",
    "\n",
    "        for i in range(steps):\n",
    "            all_masks[i] = RingImage(height,width,inner_radii[i],outer_radii[i],bandwidth=bandwidth)\n",
    "            \n",
    "    return all_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41fcc8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the ring masks took 0.0 Seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temporary_settings = {}\n",
    "temporary_settings[\"augmented_dems\"] = []\n",
    "\n",
    "# Put all the DEM maps from the dem_folder into the dem_files\n",
    "with os.scandir(internal_settings[\"files\"][\"dem_folder\"]) as dirlist:\n",
    "    temporary_settings[\"augmented_dems\"] =[AugmentedDEM(d.path, internal_settings) \n",
    "                                           for d in dirlist if re.search(r\"\\.tif\",d.name)]\n",
    "\n",
    "# Set up the masks for the weighted average\n",
    "temporary_settings[\"circle_masks\"] = RingImageSeries(internal_settings[\"fft\"][\"tile_size_px\"],\n",
    "                                                     internal_settings[\"fft\"][\"tile_size_px\"],\n",
    "                                                     internal_settings[\"fft\"][\"fft_levels\"]\n",
    "                                                     ,bandwidth = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3726fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiprocessing Resample of Tiles took 5.8 Seconds\n",
      "Creating FFT footprints took 0.4 Seconds\n",
      "Creating the weighted averages per mask took 0.7 Seconds\n",
      "Clustering took 0.1 Seconds\n",
      "Sorting Clusters took 0.0 Seconds\n",
      "(1008, 1584)\n",
      "Filtering of the mapped labels took 7.2 Seconds\n",
      "(1008, 1584, 4)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit -n 10 -r 10\n",
    "# Testing\n",
    "# Important! At the moment all the labels are created INSIDE one DEM\n",
    "# Later they should be done across all dems! \n",
    "# That will be what makes them comparable\n",
    "\n",
    "\n",
    "for d in temporary_settings[\"augmented_dems\"]:\n",
    "    d.process_dem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2be85c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
